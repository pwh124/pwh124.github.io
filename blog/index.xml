<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Paul W. Hook</title>
    <link>/blog/</link>
    <description>Recent content in Blogs on Paul W. Hook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Apr 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Scraping bioRxiv</title>
      <link>/blog/2018/04/10/2018-02-27-scraping-biorxiv-getting-started/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      <guid>/blog/2018/04/10/2018-02-27-scraping-biorxiv-getting-started/</guid>
      <description>This post is the first of a series focusing on tracking preprints on bioRxiv. The motivation behind this and a more detailed explanantion can be found here.
Scraping in R When I began to approach preprint tracking, the mysterious world of &amp;ldquo;HTML scraping&amp;rdquo; seemed like something that would help. Simply, scraping allows you to extract information from the underlying HTML (Hypertext Markup Language) documents that make up websites.
HTML scraping seemed like a good idea for preprint tracking because: A) It doesn&amp;rsquo;t seem like there are simple/easy ways to access a bioRxiv database that holds such information (especially for someone with limited experience in this like me) and B) Whether or not the paper is published in a peer-reviewed journal is displayed clearly on each preprint&amp;rsquo;s page (see below on the webpage in red).</description>
    </item>
    <item>
      <title>Keeping track of preprints</title>
      <link>/blog/2018/04/04/2018-02-25-scraping-biorxiv-part-1/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      <guid>/blog/2018/04/04/2018-02-25-scraping-biorxiv-part-1/</guid>
      <description>Premise For my first set of blog posts, I have decided to start a series about preprints. Awhile ago, an interesting question was brought up by Shannon Ellis in her wonderful blog post &amp;ldquo;Let there be preprint citations!&amp;quot; (emphasis is mine):
Problem #2: Preprints often become peer-reviewed research. How will we keep track?
Solution #2a (if this occurs during while the manuscript is being drafted): It is up to the author(s) to ensure that their manuscript is as up to date as possible upon submission for publication.</description>
    </item>
    <item>
      <title>My first blog post!</title>
      <link>/blog/2018/04/02/2018-02-20-my-first-blog-post/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      <guid>/blog/2018/04/02/2018-02-20-my-first-blog-post/</guid>
      <description>Hello! If you haven&amp;rsquo;t been able to tell by the website already, my name is Paul Hook.
I am a fourth year Ph.D. student in the Human Genetics program in the McKusick-Nathans Institute of Genetic Medicine at the Johns Hopkins University School of Medicine. I am in Dr. Andy McCallion&amp;rsquo;s lab.
You can learn a little more about me here, so I won&amp;rsquo;t go on and on in the inaugural blog post.</description>
    </item>
  </channel>
</rss>
